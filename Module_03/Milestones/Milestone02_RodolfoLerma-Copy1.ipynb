{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 02 - Refining Models\n",
    "\n",
    "## Author - Rodolfo Lerma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem\n",
    "\n",
    "Continue from Milestone 1 to build a Decision Tree, Random Forest and SVC model and compare performance.\n",
    "\n",
    "# Abstract:\n",
    "\n",
    "The capstone project focuses on diaper manufacturing quality. Generally, to ensure or predict quality, a diaper manufacturer need s to monitor every step of the manufacturing process with sensors such as heat sensors, glue sensors, glue level, etc.\n",
    "For this capstone project, we will use the SECOM manufacturing Data Set from the UCI Machine Learning Repository.\n",
    "\n",
    "The analysis is is divided the following way:\n",
    "\n",
    "### Summary from Milestone 01\n",
    "\n",
    "\n",
    "### Data Formatting\n",
    "- **Merging Data**\n",
    "- **Missing Data**\n",
    "\n",
    "### Evaluation of the Features for Future Models.\n",
    "- **Train & Test Model**\n",
    "\n",
    "### Summary/Conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary from Milestone 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Fromatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load File\n",
    "filename = 'secom.data'\n",
    "filename2 = 'secom_labels.data'\n",
    "data = pd.read_csv(filename,header=None, sep = '\\s+')\n",
    "others = pd.read_csv(filename2,header=None,sep = '\\s+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "others.columns = ['target', 'date']\n",
    "df = pd.concat([others,data], axis = 1)\n",
    "df['date']= pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = []\n",
    "my_list = df.columns.values.tolist()\n",
    "y = df.shape\n",
    "for i in my_list:\n",
    "    x = df[i].isnull().sum()\n",
    "    missing_values.append(x)\n",
    "    \n",
    "columns_missing = dict(zip(my_list, missing_values))\n",
    "a = sorted(columns_missing.items(), key=lambda x: x[1], reverse = True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before if more than 15% of data is missing in a column that column would be dropped from this data set at this moment. For other columns with missing data is present depending on how much data is missing is going to be either dropped or imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_columns_names = []\n",
    "for key, value in columns_missing.items():\n",
    "    if value > 240: #15% of the data\n",
    "        x = key\n",
    "        missing_columns_names.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those columns would be eliminated from the data set, since most of the values are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(missing_columns_names, axis = 1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this analysis since removing missing data would only take 10% of the available data, those raws are going to be remove. If by removing missing data more than 15% were to be removed other methods would have been explored as: substitution.\n",
    "Even at this moment having 540 variables/features is to much to explore and obtain meaninful results, therefore more work has to be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeated Values (Columns with the same value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_repeated = []\n",
    "repeated = []\n",
    "updated_columns = df.columns.values.tolist()\n",
    "y = df.shape\n",
    "for i in updated_columns[2:]:\n",
    "    x = df[i].std()\n",
    "    if x == 0:\n",
    "        repeated.append(i)\n",
    "    else:\n",
    "        not_repeated.append(i)\n",
    "df = df.drop(repeated, axis = 1)\n",
    "\n",
    "categorical = []\n",
    "numerical = []\n",
    "updated_columns = df.columns.values.tolist()\n",
    "y = df.shape\n",
    "for i in updated_columns:\n",
    "    x = df[i].dtypes\n",
    "    if x == object:\n",
    "        categorical.append(i)\n",
    "    else:\n",
    "        numerical.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thru the code above the data was checked to see if there was any variable that could be considered as categorical (also this helped to checked any column with incorrect values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "From Milestone 01 it was seen that the best Features where does coming from the Wrapper Method. For more details on this comparison see Milestone 01 analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Feature Elimination\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.feature_selection import RFE #Recursive Feature Elimination\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "estimator = LinearRegression()\n",
    "selector = RFE(estimator, 50, step=1)\n",
    "\n",
    "df_numeric = df[numerical]\n",
    "df_numeric = df_numeric.drop('date', axis = 1)\n",
    "\n",
    "df_numeric_copy = df_numeric.copy()\n",
    "\n",
    "target = df_numeric.iloc[:,0]#This is the selection of the Target Variables\n",
    "df_updated = df_numeric_copy.drop('target', axis='columns')\n",
    "\n",
    "lol = df_updated.values.tolist()\n",
    "selector = selector.fit(lol, target)\n",
    "\n",
    "boolean_values = selector.support_\n",
    "ranking_values = selector.ranking_\n",
    "wrapper_columns = df_updated.columns.values.tolist()\n",
    "\n",
    "#Selection of the features with ranking 1\n",
    "selected_features = []\n",
    "unselected_features = []\n",
    "for i in range(len(wrapper_columns)):\n",
    "    w = boolean_values[i]\n",
    "    if w == True:\n",
    "        b = wrapper_columns[i]\n",
    "        selected_features.append(b)\n",
    "    else:\n",
    "        v = wrapper_columns[i]\n",
    "        unselected_features.append(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data and Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "\n",
    "tr = df.iloc[:,0].tolist()\n",
    "binomial = []\n",
    "for i in range(len(tr)):\n",
    "    b = tr[i]\n",
    "    if b < 0:\n",
    "        n = 0\n",
    "    else:\n",
    "        n = 1\n",
    "    binomial.append(n)\n",
    "df['target_binomial'] = binomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data for variables with high mi value\n",
    "label = df['target_binomial']\n",
    "variables = df[selected_features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(variables, label, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "variables_sm, label_sm = sm.fit_resample(variables, label)\n",
    "\n",
    "X_train_sm, X_test_sm, y_train_sm, y_test_sm = train_test_split(variables_sm, label_sm, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary the variables that are going to be input to the model are:\n",
    "- Training:\n",
    "    - `X_train_sm`\n",
    "    - `y_train_sm`\n",
    "    \n",
    "    \n",
    "- Testing:\n",
    "    - `X_test`\n",
    "    - `y_test`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Settings for the `Decision Tree` Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_options = [2,3,4,5,6,7,8,9,10]\n",
    "min_sample_options = [2,3,4,5,6,7,8,9,10]\n",
    "model_criterion = ['entropy', 'gini']\n",
    "min_samples_leaf_options = [2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "dt_grid = {'criterion': model_criterion, \n",
    "           'max_depth': max_depth_options,\n",
    "           'min_samples_split':min_sample_options,\n",
    "           'min_samples_leaf':min_samples_leaf_options}\n",
    "\n",
    "dt_base = DecisionTreeClassifier()\n",
    "\n",
    "decision_trees_hyper = RandomizedSearchCV(estimator = dt_base, param_distributions = dt_grid, \n",
    "                               n_iter = 200, cv = 3, verbose = 2, random_state = 42, \n",
    "                               n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "decision_trees_hyper.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "x = decision_trees_hyper.best_params_\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Settings for the `Random Forest` Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_options = [10,20,30,40,50,60,70,80,90,100]\n",
    "\n",
    "rf_grid = {'criterion': model_criterion,\n",
    "           'n_estimators':n_estimators_options, \n",
    "           'max_depth': max_depth_options,\n",
    "           'min_samples_split':min_sample_options,\n",
    "           'min_samples_leaf':min_samples_leaf_options}\n",
    "\n",
    "rf_base = RandomForestClassifier()\n",
    "\n",
    "random_forest_hyper = RandomizedSearchCV(estimator = rf_base, param_distributions = rf_grid, \n",
    "                               n_iter = 200, cv = 3, verbose = 2, random_state = 42, \n",
    "                               n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "random_forest_hyper.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "y = random_forest_hyper.best_params_\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Settings for the `SVC` Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_options = ['linear','poly','rbf']\n",
    "cost_options = [0.8, 0.9, 1.0, 1.1, 1.2]\n",
    "gamma_options = ['scale', 'auto']\n",
    "degree_options = [3,4,5,6]\n",
    "\n",
    "svc_grid = {'kernel': kernel_options, \n",
    "           'C': cost_options,\n",
    "           'gamma':gamma_options,\n",
    "           'degree':degree_options}\n",
    "\n",
    "svc_base = svm.SVC()\n",
    "\n",
    "svc_hyper = RandomizedSearchCV(estimator = svc_base, param_distributions = svc_grid, \n",
    "                               n_iter = 200, cv = 3, verbose = 2, random_state = 42, \n",
    "                               n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "svc_hyper.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "z = svc_hyper.best_params_\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfomance_values(T,Y,header):\n",
    "    print(\"Classifier: \", header)\n",
    "    # Confusion Matrix\n",
    "    CM = confusion_matrix(T, Y)\n",
    "    #print (\"\\n\\nConfusion matrix:\\n\", CM)\n",
    "    tn, fp, fn, tp = CM.ravel()\n",
    "    #print (\"\\nTP, TN, FP, FN:\", tp, \",\", tn, \",\", fp, \",\", fn)\n",
    "    AR = accuracy_score(T, Y)\n",
    "    ER = 1.0 - AR\n",
    "    P = precision_score(T, Y)\n",
    "    R = recall_score(T, Y)\n",
    "    F1 = f1_score(T, Y)\n",
    "    print (\"\\nAccuracy:\", round(AR,4), \",Error Rate:\", round(ER,4), \",Precision:\", round(P,4), \",Recall:\", round(R,4), \",F1 Score:\",round(F1,4))\n",
    "    print (\" \")\n",
    "    return AR, ER, P, R, F1\n",
    "\n",
    "#Function to make sure the output is a boolean as it is needed for the roc_curve\n",
    "def booleans(vector):\n",
    "    final = []\n",
    "    for i in vector:\n",
    "        if i == 1:\n",
    "            i = 0\n",
    "        else:\n",
    "            i = 1\n",
    "        final.append(i)\n",
    "    return final\n",
    "\n",
    "#Function to train the model and obtain the perfomance values from each model (in a plot form)\n",
    "def classifier_performance(V, header, X_train, X_test, y_train, y_test):\n",
    "    accuracy_rate = []\n",
    "    error_rate = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1_score = []\n",
    "    for i in range(len(header)):\n",
    "        V[i].fit(X_train, y_train)\n",
    "        proba = V[i].predict_proba(X_test)[:,1]#Predictions and probabilities\n",
    "        prediction = V[i].predict(X_test)\n",
    "        #Creating a Data Frame for the Test, Prediction and Probaility Data\n",
    "        T = y_test.values.tolist()\n",
    "        Y = prediction.tolist()\n",
    "        y = proba.tolist()\n",
    "        Y = booleans(Y)\n",
    "        T = booleans(T)\n",
    "        AR, ER, P, R, F1 = perfomance_values(T,Y,header[i])\n",
    "        accuracy_rate.append(AR)\n",
    "        error_rate.append(ER)\n",
    "        precision.append(P)\n",
    "        recall.append(R)\n",
    "        f1_score.append(F1)\n",
    "        allvalues = [AR, ER, P, R, F1]\n",
    "    return allvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifiers\n",
    "dt = DecisionTreeClassifier(criterion=x['criterion'], max_depth = x['max_depth'], min_samples_split = x['min_samples_split'], min_samples_leaf = x['min_samples_leaf'])\n",
    "rf = RandomForestClassifier(n_estimators = y['n_estimators'], criterion = y['criterion'], max_depth = y['max_depth'], min_samples_split = y['min_samples_split'], min_samples_leaf = y['min_samples_leaf'])\n",
    "svc = svm.SVC(gamma=z['gamma'], kernel = z['kernel'], C = z['C'], degree = z['degree'], probability=True)\n",
    "\n",
    "#List for Classifiers and Names\n",
    "header = [\"Decision_Tree\",\"Random_Forest\", \"SVC\"]\n",
    "V = [dt, rf, svc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running and obtaining performance values from the Models listed above\n",
    "classifier_performance(V, header, X_train_sm, X_test, y_train_sm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Models Performance\n",
    "\n",
    "### Decision Tree\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "### SVC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
